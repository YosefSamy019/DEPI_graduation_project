{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 100,
  "global_step": 2025,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014814814814814815,
      "grad_norm": 1.2156713008880615,
      "learning_rate": 4.926108374384237e-06,
      "loss": 0.7179,
      "step": 10
    },
    {
      "epoch": 0.02962962962962963,
      "grad_norm": 1.2225691080093384,
      "learning_rate": 9.852216748768475e-06,
      "loss": 0.6233,
      "step": 20
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 1.0268605947494507,
      "learning_rate": 1.4778325123152711e-05,
      "loss": 0.5726,
      "step": 30
    },
    {
      "epoch": 0.05925925925925926,
      "grad_norm": 0.9700405597686768,
      "learning_rate": 1.970443349753695e-05,
      "loss": 0.6557,
      "step": 40
    },
    {
      "epoch": 0.07407407407407407,
      "grad_norm": 1.1797800064086914,
      "learning_rate": 2.4630541871921184e-05,
      "loss": 0.4733,
      "step": 50
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 1.0230956077575684,
      "learning_rate": 2.9556650246305422e-05,
      "loss": 0.4728,
      "step": 60
    },
    {
      "epoch": 0.1037037037037037,
      "grad_norm": 1.2278790473937988,
      "learning_rate": 3.4482758620689657e-05,
      "loss": 0.5822,
      "step": 70
    },
    {
      "epoch": 0.11851851851851852,
      "grad_norm": 1.0116655826568604,
      "learning_rate": 3.94088669950739e-05,
      "loss": 0.5249,
      "step": 80
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 1.1166661977767944,
      "learning_rate": 4.433497536945813e-05,
      "loss": 0.4369,
      "step": 90
    },
    {
      "epoch": 0.14814814814814814,
      "grad_norm": 1.0451099872589111,
      "learning_rate": 4.926108374384237e-05,
      "loss": 0.4779,
      "step": 100
    },
    {
      "epoch": 0.14814814814814814,
      "eval_loss": 0.403049111366272,
      "eval_runtime": 21.1363,
      "eval_samples_per_second": 3.123,
      "eval_steps_per_second": 3.123,
      "step": 100
    },
    {
      "epoch": 0.16296296296296298,
      "grad_norm": 1.3517301082611084,
      "learning_rate": 5.41871921182266e-05,
      "loss": 0.4992,
      "step": 110
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 0.8995790481567383,
      "learning_rate": 5.9113300492610844e-05,
      "loss": 0.4143,
      "step": 120
    },
    {
      "epoch": 0.1925925925925926,
      "grad_norm": 0.8969790935516357,
      "learning_rate": 6.403940886699507e-05,
      "loss": 0.4708,
      "step": 130
    },
    {
      "epoch": 0.2074074074074074,
      "grad_norm": 0.9727891683578491,
      "learning_rate": 6.896551724137931e-05,
      "loss": 0.4942,
      "step": 140
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 0.9361456036567688,
      "learning_rate": 7.389162561576355e-05,
      "loss": 0.4346,
      "step": 150
    },
    {
      "epoch": 0.23703703703703705,
      "grad_norm": 0.9902341961860657,
      "learning_rate": 7.88177339901478e-05,
      "loss": 0.4257,
      "step": 160
    },
    {
      "epoch": 0.2518518518518518,
      "grad_norm": 0.9778716564178467,
      "learning_rate": 8.374384236453202e-05,
      "loss": 0.4637,
      "step": 170
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.9112097024917603,
      "learning_rate": 8.866995073891627e-05,
      "loss": 0.4222,
      "step": 180
    },
    {
      "epoch": 0.2814814814814815,
      "grad_norm": 0.8872127532958984,
      "learning_rate": 9.35960591133005e-05,
      "loss": 0.4477,
      "step": 190
    },
    {
      "epoch": 0.2962962962962963,
      "grad_norm": 0.8276744484901428,
      "learning_rate": 9.852216748768474e-05,
      "loss": 0.3938,
      "step": 200
    },
    {
      "epoch": 0.2962962962962963,
      "eval_loss": 0.38652917742729187,
      "eval_runtime": 21.065,
      "eval_samples_per_second": 3.133,
      "eval_steps_per_second": 3.133,
      "step": 200
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 0.8540408611297607,
      "learning_rate": 9.999635805136378e-05,
      "loss": 0.4313,
      "step": 210
    },
    {
      "epoch": 0.32592592592592595,
      "grad_norm": 1.06760835647583,
      "learning_rate": 9.997852121279563e-05,
      "loss": 0.4519,
      "step": 220
    },
    {
      "epoch": 0.34074074074074073,
      "grad_norm": 1.027531623840332,
      "learning_rate": 9.99458258511845e-05,
      "loss": 0.4194,
      "step": 230
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.9014073610305786,
      "learning_rate": 9.989828168680164e-05,
      "loss": 0.4125,
      "step": 240
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.7499438524246216,
      "learning_rate": 9.983590285444024e-05,
      "loss": 0.4367,
      "step": 250
    },
    {
      "epoch": 0.3851851851851852,
      "grad_norm": 0.7590578198432922,
      "learning_rate": 9.975870789921322e-05,
      "loss": 0.4664,
      "step": 260
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.8644533157348633,
      "learning_rate": 9.966671977103972e-05,
      "loss": 0.3825,
      "step": 270
    },
    {
      "epoch": 0.4148148148148148,
      "grad_norm": 0.798233687877655,
      "learning_rate": 9.955996581782219e-05,
      "loss": 0.3899,
      "step": 280
    },
    {
      "epoch": 0.42962962962962964,
      "grad_norm": 0.8980532288551331,
      "learning_rate": 9.943847777731584e-05,
      "loss": 0.4522,
      "step": 290
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.9683994054794312,
      "learning_rate": 9.93022917676932e-05,
      "loss": 0.5203,
      "step": 300
    },
    {
      "epoch": 0.4444444444444444,
      "eval_loss": 0.36775702238082886,
      "eval_runtime": 21.0662,
      "eval_samples_per_second": 3.133,
      "eval_steps_per_second": 3.133,
      "step": 300
    },
    {
      "epoch": 0.45925925925925926,
      "grad_norm": 0.8769967555999756,
      "learning_rate": 9.915144827680604e-05,
      "loss": 0.4705,
      "step": 310
    },
    {
      "epoch": 0.4740740740740741,
      "grad_norm": 0.856913685798645,
      "learning_rate": 9.898599215014867e-05,
      "loss": 0.397,
      "step": 320
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 0.7433983087539673,
      "learning_rate": 9.880597257752522e-05,
      "loss": 0.3909,
      "step": 330
    },
    {
      "epoch": 0.5037037037037037,
      "grad_norm": 0.7787937521934509,
      "learning_rate": 9.861144307842574e-05,
      "loss": 0.3825,
      "step": 340
    },
    {
      "epoch": 0.5185185185185185,
      "grad_norm": 0.7537899017333984,
      "learning_rate": 9.840246148611485e-05,
      "loss": 0.4406,
      "step": 350
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.7275124192237854,
      "learning_rate": 9.817908993043819e-05,
      "loss": 0.4013,
      "step": 360
    },
    {
      "epoch": 0.5481481481481482,
      "grad_norm": 0.873802661895752,
      "learning_rate": 9.794139481935107e-05,
      "loss": 0.3969,
      "step": 370
    },
    {
      "epoch": 0.562962962962963,
      "grad_norm": 0.6794826984405518,
      "learning_rate": 9.768944681917582e-05,
      "loss": 0.3508,
      "step": 380
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 0.6884282231330872,
      "learning_rate": 9.742332083359251e-05,
      "loss": 0.394,
      "step": 390
    },
    {
      "epoch": 0.5925925925925926,
      "grad_norm": 0.720268189907074,
      "learning_rate": 9.714309598137045e-05,
      "loss": 0.4821,
      "step": 400
    },
    {
      "epoch": 0.5925925925925926,
      "eval_loss": 0.3522947132587433,
      "eval_runtime": 21.1519,
      "eval_samples_per_second": 3.12,
      "eval_steps_per_second": 3.12,
      "step": 400
    },
    {
      "epoch": 0.6074074074074074,
      "grad_norm": 0.780142605304718,
      "learning_rate": 9.68488555728462e-05,
      "loss": 0.4085,
      "step": 410
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 0.6438445448875427,
      "learning_rate": 9.654068708515565e-05,
      "loss": 0.3829,
      "step": 420
    },
    {
      "epoch": 0.6370370370370371,
      "grad_norm": 0.7742606401443481,
      "learning_rate": 9.621868213622713e-05,
      "loss": 0.5205,
      "step": 430
    },
    {
      "epoch": 0.6518518518518519,
      "grad_norm": 0.7930306196212769,
      "learning_rate": 9.588293645754363e-05,
      "loss": 0.4431,
      "step": 440
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.7679243683815002,
      "learning_rate": 9.553354986568202e-05,
      "loss": 0.4123,
      "step": 450
    },
    {
      "epoch": 0.6814814814814815,
      "grad_norm": 0.7643994092941284,
      "learning_rate": 9.517062623263768e-05,
      "loss": 0.3871,
      "step": 460
    },
    {
      "epoch": 0.6962962962962963,
      "grad_norm": 0.7332501411437988,
      "learning_rate": 9.479427345494367e-05,
      "loss": 0.4678,
      "step": 470
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.8016829490661621,
      "learning_rate": 9.440460342159314e-05,
      "loss": 0.4621,
      "step": 480
    },
    {
      "epoch": 0.725925925925926,
      "grad_norm": 0.7249430418014526,
      "learning_rate": 9.400173198077509e-05,
      "loss": 0.3557,
      "step": 490
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.7589895129203796,
      "learning_rate": 9.358577890543278e-05,
      "loss": 0.3828,
      "step": 500
    },
    {
      "epoch": 0.7407407407407407,
      "eval_loss": 0.3402881622314453,
      "eval_runtime": 21.0555,
      "eval_samples_per_second": 3.135,
      "eval_steps_per_second": 3.135,
      "step": 500
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 0.7056297659873962,
      "learning_rate": 9.315686785765556e-05,
      "loss": 0.4241,
      "step": 510
    },
    {
      "epoch": 0.7703703703703704,
      "grad_norm": 0.7447760105133057,
      "learning_rate": 9.271512635191428e-05,
      "loss": 0.455,
      "step": 520
    },
    {
      "epoch": 0.7851851851851852,
      "grad_norm": 0.8702666163444519,
      "learning_rate": 9.226068571715149e-05,
      "loss": 0.3998,
      "step": 530
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.7768734693527222,
      "learning_rate": 9.179368105773767e-05,
      "loss": 0.4211,
      "step": 540
    },
    {
      "epoch": 0.8148148148148148,
      "grad_norm": 0.7299871444702148,
      "learning_rate": 9.131425121330477e-05,
      "loss": 0.3395,
      "step": 550
    },
    {
      "epoch": 0.8296296296296296,
      "grad_norm": 0.7543619871139526,
      "learning_rate": 9.082253871746962e-05,
      "loss": 0.4029,
      "step": 560
    },
    {
      "epoch": 0.8444444444444444,
      "grad_norm": 0.662013053894043,
      "learning_rate": 9.031868975545884e-05,
      "loss": 0.3443,
      "step": 570
    },
    {
      "epoch": 0.8592592592592593,
      "grad_norm": 0.7910561561584473,
      "learning_rate": 8.980285412064828e-05,
      "loss": 0.4058,
      "step": 580
    },
    {
      "epoch": 0.8740740740740741,
      "grad_norm": 0.9646458625793457,
      "learning_rate": 8.927518517002969e-05,
      "loss": 0.4513,
      "step": 590
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.70588219165802,
      "learning_rate": 8.8735839778618e-05,
      "loss": 0.4154,
      "step": 600
    },
    {
      "epoch": 0.8888888888888888,
      "eval_loss": 0.3396819531917572,
      "eval_runtime": 21.121,
      "eval_samples_per_second": 3.125,
      "eval_steps_per_second": 3.125,
      "step": 600
    },
    {
      "epoch": 0.9037037037037037,
      "grad_norm": 0.8189159035682678,
      "learning_rate": 8.818497829281272e-05,
      "loss": 0.3847,
      "step": 610
    },
    {
      "epoch": 0.9185185185185185,
      "grad_norm": 0.7504698634147644,
      "learning_rate": 8.762276448272708e-05,
      "loss": 0.401,
      "step": 620
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 0.834638237953186,
      "learning_rate": 8.704936549349961e-05,
      "loss": 0.4097,
      "step": 630
    },
    {
      "epoch": 0.9481481481481482,
      "grad_norm": 0.766274631023407,
      "learning_rate": 8.646495179560222e-05,
      "loss": 0.3993,
      "step": 640
    },
    {
      "epoch": 0.9629629629629629,
      "grad_norm": 0.7892537713050842,
      "learning_rate": 8.586969713415948e-05,
      "loss": 0.3973,
      "step": 650
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 0.6971818804740906,
      "learning_rate": 8.526377847729474e-05,
      "loss": 0.3872,
      "step": 660
    },
    {
      "epoch": 0.9925925925925926,
      "grad_norm": 0.6884809732437134,
      "learning_rate": 8.464737596351759e-05,
      "loss": 0.4517,
      "step": 670
    },
    {
      "epoch": 1.0074074074074073,
      "grad_norm": 0.569403350353241,
      "learning_rate": 8.402067284816919e-05,
      "loss": 0.341,
      "step": 680
    },
    {
      "epoch": 1.0222222222222221,
      "grad_norm": 0.6368958353996277,
      "learning_rate": 8.338385544894071e-05,
      "loss": 0.2415,
      "step": 690
    },
    {
      "epoch": 1.037037037037037,
      "grad_norm": 0.6876741051673889,
      "learning_rate": 8.273711309048144e-05,
      "loss": 0.2703,
      "step": 700
    },
    {
      "epoch": 1.037037037037037,
      "eval_loss": 0.33609429001808167,
      "eval_runtime": 21.1289,
      "eval_samples_per_second": 3.124,
      "eval_steps_per_second": 3.124,
      "step": 700
    },
    {
      "epoch": 1.0518518518518518,
      "grad_norm": 0.7650197744369507,
      "learning_rate": 8.208063804811292e-05,
      "loss": 0.327,
      "step": 710
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 0.708203911781311,
      "learning_rate": 8.141462549066582e-05,
      "loss": 0.2662,
      "step": 720
    },
    {
      "epoch": 1.0814814814814815,
      "grad_norm": 0.9478704333305359,
      "learning_rate": 8.073927342245663e-05,
      "loss": 0.29,
      "step": 730
    },
    {
      "epoch": 1.0962962962962963,
      "grad_norm": 0.9072978496551514,
      "learning_rate": 8.005478262442133e-05,
      "loss": 0.2769,
      "step": 740
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.6874735355377197,
      "learning_rate": 7.936135659442355e-05,
      "loss": 0.281,
      "step": 750
    },
    {
      "epoch": 1.125925925925926,
      "grad_norm": 0.7664161920547485,
      "learning_rate": 7.86592014867551e-05,
      "loss": 0.2882,
      "step": 760
    },
    {
      "epoch": 1.1407407407407408,
      "grad_norm": 0.7571979761123657,
      "learning_rate": 7.794852605084662e-05,
      "loss": 0.2881,
      "step": 770
    },
    {
      "epoch": 1.1555555555555554,
      "grad_norm": 0.8744916915893555,
      "learning_rate": 7.722954156920675e-05,
      "loss": 0.2428,
      "step": 780
    },
    {
      "epoch": 1.1703703703703703,
      "grad_norm": 0.8967177271842957,
      "learning_rate": 7.650246179460824e-05,
      "loss": 0.3069,
      "step": 790
    },
    {
      "epoch": 1.1851851851851851,
      "grad_norm": 0.833340048789978,
      "learning_rate": 7.57675028865397e-05,
      "loss": 0.2253,
      "step": 800
    },
    {
      "epoch": 1.1851851851851851,
      "eval_loss": 0.33827704191207886,
      "eval_runtime": 21.1332,
      "eval_samples_per_second": 3.123,
      "eval_steps_per_second": 3.123,
      "step": 800
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.757311999797821,
      "learning_rate": 7.502488334694166e-05,
      "loss": 0.2367,
      "step": 810
    },
    {
      "epoch": 1.2148148148148148,
      "grad_norm": 0.7344473004341125,
      "learning_rate": 7.427482395524645e-05,
      "loss": 0.2738,
      "step": 820
    },
    {
      "epoch": 1.2296296296296296,
      "grad_norm": 1.0388681888580322,
      "learning_rate": 7.35175477027408e-05,
      "loss": 0.2893,
      "step": 830
    },
    {
      "epoch": 1.2444444444444445,
      "grad_norm": 0.6464024782180786,
      "learning_rate": 7.2753279726271e-05,
      "loss": 0.2645,
      "step": 840
    },
    {
      "epoch": 1.2592592592592593,
      "grad_norm": 0.6919133067131042,
      "learning_rate": 7.198224724131012e-05,
      "loss": 0.2803,
      "step": 850
    },
    {
      "epoch": 1.2740740740740741,
      "grad_norm": 0.6624501347541809,
      "learning_rate": 7.120467947440719e-05,
      "loss": 0.2798,
      "step": 860
    },
    {
      "epoch": 1.2888888888888888,
      "grad_norm": 0.7350782752037048,
      "learning_rate": 7.042080759503866e-05,
      "loss": 0.2598,
      "step": 870
    },
    {
      "epoch": 1.3037037037037038,
      "grad_norm": 0.7518550157546997,
      "learning_rate": 6.963086464688208e-05,
      "loss": 0.2865,
      "step": 880
    },
    {
      "epoch": 1.3185185185185184,
      "grad_norm": 0.7434231638908386,
      "learning_rate": 6.883508547853267e-05,
      "loss": 0.2378,
      "step": 890
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.8423694968223572,
      "learning_rate": 6.803370667368328e-05,
      "loss": 0.2677,
      "step": 900
    },
    {
      "epoch": 1.3333333333333333,
      "eval_loss": 0.3322671055793762,
      "eval_runtime": 21.1243,
      "eval_samples_per_second": 3.124,
      "eval_steps_per_second": 3.124,
      "step": 900
    },
    {
      "epoch": 1.348148148148148,
      "grad_norm": 0.8216996192932129,
      "learning_rate": 6.722696648078838e-05,
      "loss": 0.251,
      "step": 910
    },
    {
      "epoch": 1.362962962962963,
      "grad_norm": 0.6975584030151367,
      "learning_rate": 6.641510474223338e-05,
      "loss": 0.2795,
      "step": 920
    },
    {
      "epoch": 1.3777777777777778,
      "grad_norm": 0.7641984820365906,
      "learning_rate": 6.559836282302983e-05,
      "loss": 0.2608,
      "step": 930
    },
    {
      "epoch": 1.3925925925925926,
      "grad_norm": 0.6547947525978088,
      "learning_rate": 6.477698353905808e-05,
      "loss": 0.2522,
      "step": 940
    },
    {
      "epoch": 1.4074074074074074,
      "grad_norm": 0.7414109706878662,
      "learning_rate": 6.395121108487855e-05,
      "loss": 0.2571,
      "step": 950
    },
    {
      "epoch": 1.4222222222222223,
      "grad_norm": 0.98086017370224,
      "learning_rate": 6.312129096113312e-05,
      "loss": 0.2607,
      "step": 960
    },
    {
      "epoch": 1.4370370370370371,
      "grad_norm": 1.0194066762924194,
      "learning_rate": 6.22874699015583e-05,
      "loss": 0.2528,
      "step": 970
    },
    {
      "epoch": 1.4518518518518517,
      "grad_norm": 0.6347277760505676,
      "learning_rate": 6.144999579963164e-05,
      "loss": 0.3087,
      "step": 980
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 0.7198352217674255,
      "learning_rate": 6.060911763487354e-05,
      "loss": 0.3414,
      "step": 990
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 0.6187707185745239,
      "learning_rate": 5.976508539882604e-05,
      "loss": 0.2723,
      "step": 1000
    },
    {
      "epoch": 1.4814814814814814,
      "eval_loss": 0.3259091079235077,
      "eval_runtime": 21.143,
      "eval_samples_per_second": 3.122,
      "eval_steps_per_second": 3.122,
      "step": 1000
    },
    {
      "epoch": 1.4962962962962962,
      "grad_norm": 0.6343087553977966,
      "learning_rate": 5.891815002073081e-05,
      "loss": 0.2903,
      "step": 1010
    },
    {
      "epoch": 1.511111111111111,
      "grad_norm": 0.7058057188987732,
      "learning_rate": 5.806856329292839e-05,
      "loss": 0.2877,
      "step": 1020
    },
    {
      "epoch": 1.525925925925926,
      "grad_norm": 0.5926945805549622,
      "learning_rate": 5.721657779600072e-05,
      "loss": 0.2566,
      "step": 1030
    },
    {
      "epoch": 1.5407407407407407,
      "grad_norm": 0.6769628524780273,
      "learning_rate": 5.636244682367937e-05,
      "loss": 0.2995,
      "step": 1040
    },
    {
      "epoch": 1.5555555555555556,
      "grad_norm": 0.7235645055770874,
      "learning_rate": 5.5506424307541895e-05,
      "loss": 0.2486,
      "step": 1050
    },
    {
      "epoch": 1.5703703703703704,
      "grad_norm": 0.7709996700286865,
      "learning_rate": 5.4648764741518344e-05,
      "loss": 0.3668,
      "step": 1060
    },
    {
      "epoch": 1.585185185185185,
      "grad_norm": 0.7575385570526123,
      "learning_rate": 5.378972310623067e-05,
      "loss": 0.3019,
      "step": 1070
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6540639400482178,
      "learning_rate": 5.292955479318756e-05,
      "loss": 0.2427,
      "step": 1080
    },
    {
      "epoch": 1.6148148148148147,
      "grad_norm": 0.7067882418632507,
      "learning_rate": 5.206851552885691e-05,
      "loss": 0.2859,
      "step": 1090
    },
    {
      "epoch": 1.6296296296296298,
      "grad_norm": 0.9452317357063293,
      "learning_rate": 5.120686129863882e-05,
      "loss": 0.3145,
      "step": 1100
    },
    {
      "epoch": 1.6296296296296298,
      "eval_loss": 0.32769539952278137,
      "eval_runtime": 21.1459,
      "eval_samples_per_second": 3.121,
      "eval_steps_per_second": 3.121,
      "step": 1100
    },
    {
      "epoch": 1.6444444444444444,
      "grad_norm": 0.6808127760887146,
      "learning_rate": 5.0344848270761635e-05,
      "loss": 0.2576,
      "step": 1110
    },
    {
      "epoch": 1.6592592592592592,
      "grad_norm": 0.7522488236427307,
      "learning_rate": 4.948273272012362e-05,
      "loss": 0.2422,
      "step": 1120
    },
    {
      "epoch": 1.674074074074074,
      "grad_norm": 0.6745529770851135,
      "learning_rate": 4.8620770952102836e-05,
      "loss": 0.2753,
      "step": 1130
    },
    {
      "epoch": 1.6888888888888889,
      "grad_norm": 0.6740512847900391,
      "learning_rate": 4.7759219226358056e-05,
      "loss": 0.2845,
      "step": 1140
    },
    {
      "epoch": 1.7037037037037037,
      "grad_norm": 0.7210848927497864,
      "learning_rate": 4.6898333680643254e-05,
      "loss": 0.2488,
      "step": 1150
    },
    {
      "epoch": 1.7185185185185186,
      "grad_norm": 0.9618678092956543,
      "learning_rate": 4.603837025465829e-05,
      "loss": 0.256,
      "step": 1160
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 0.7502437233924866,
      "learning_rate": 4.517958461395846e-05,
      "loss": 0.2514,
      "step": 1170
    },
    {
      "epoch": 1.748148148148148,
      "grad_norm": 0.8109889030456543,
      "learning_rate": 4.432223207394577e-05,
      "loss": 0.2448,
      "step": 1180
    },
    {
      "epoch": 1.762962962962963,
      "grad_norm": 0.6486709117889404,
      "learning_rate": 4.346656752396387e-05,
      "loss": 0.2931,
      "step": 1190
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 0.7482115626335144,
      "learning_rate": 4.261284535152016e-05,
      "loss": 0.2413,
      "step": 1200
    },
    {
      "epoch": 1.7777777777777777,
      "eval_loss": 0.32382825016975403,
      "eval_runtime": 21.1453,
      "eval_samples_per_second": 3.121,
      "eval_steps_per_second": 3.121,
      "step": 1200
    },
    {
      "epoch": 1.7925925925925927,
      "grad_norm": 0.6949169635772705,
      "learning_rate": 4.176131936665669e-05,
      "loss": 0.2661,
      "step": 1210
    },
    {
      "epoch": 1.8074074074074074,
      "grad_norm": 0.7152189612388611,
      "learning_rate": 4.0912242726492996e-05,
      "loss": 0.2331,
      "step": 1220
    },
    {
      "epoch": 1.8222222222222222,
      "grad_norm": 0.7820372581481934,
      "learning_rate": 4.0065867859962846e-05,
      "loss": 0.2738,
      "step": 1230
    },
    {
      "epoch": 1.837037037037037,
      "grad_norm": 1.0140715837478638,
      "learning_rate": 3.922244639276773e-05,
      "loss": 0.2732,
      "step": 1240
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 0.6766672730445862,
      "learning_rate": 3.838222907256884e-05,
      "loss": 0.306,
      "step": 1250
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 0.7102984189987183,
      "learning_rate": 3.754546569444036e-05,
      "loss": 0.3044,
      "step": 1260
    },
    {
      "epoch": 1.8814814814814815,
      "grad_norm": 0.8039059638977051,
      "learning_rate": 3.671240502660579e-05,
      "loss": 0.251,
      "step": 1270
    },
    {
      "epoch": 1.8962962962962964,
      "grad_norm": 1.01278555393219,
      "learning_rate": 3.588329473647961e-05,
      "loss": 0.3023,
      "step": 1280
    },
    {
      "epoch": 1.911111111111111,
      "grad_norm": 0.6983041167259216,
      "learning_rate": 3.5058381317036285e-05,
      "loss": 0.2656,
      "step": 1290
    },
    {
      "epoch": 1.925925925925926,
      "grad_norm": 0.7360900044441223,
      "learning_rate": 3.423791001352823e-05,
      "loss": 0.292,
      "step": 1300
    },
    {
      "epoch": 1.925925925925926,
      "eval_loss": 0.3214051127433777,
      "eval_runtime": 21.1355,
      "eval_samples_per_second": 3.123,
      "eval_steps_per_second": 3.123,
      "step": 1300
    },
    {
      "epoch": 1.9407407407407407,
      "grad_norm": 0.8443998098373413,
      "learning_rate": 3.34221247505749e-05,
      "loss": 0.2834,
      "step": 1310
    },
    {
      "epoch": 1.9555555555555557,
      "grad_norm": 0.7796865701675415,
      "learning_rate": 3.261126805964453e-05,
      "loss": 0.37,
      "step": 1320
    },
    {
      "epoch": 1.9703703703703703,
      "grad_norm": 0.6327115893363953,
      "learning_rate": 3.180558100694985e-05,
      "loss": 0.3069,
      "step": 1330
    },
    {
      "epoch": 1.9851851851851852,
      "grad_norm": 0.6944409608840942,
      "learning_rate": 3.100530312177956e-05,
      "loss": 0.2857,
      "step": 1340
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6874443888664246,
      "learning_rate": 3.0210672325286803e-05,
      "loss": 0.257,
      "step": 1350
    },
    {
      "epoch": 2.0148148148148146,
      "grad_norm": 0.6151140928268433,
      "learning_rate": 2.9421924859755524e-05,
      "loss": 0.1746,
      "step": 1360
    },
    {
      "epoch": 2.0296296296296297,
      "grad_norm": 0.6569005846977234,
      "learning_rate": 2.8639295218366112e-05,
      "loss": 0.1826,
      "step": 1370
    },
    {
      "epoch": 2.0444444444444443,
      "grad_norm": 0.5583528280258179,
      "learning_rate": 2.7863016075481096e-05,
      "loss": 0.1546,
      "step": 1380
    },
    {
      "epoch": 2.0592592592592593,
      "grad_norm": 0.6407742500305176,
      "learning_rate": 2.709331821747133e-05,
      "loss": 0.1358,
      "step": 1390
    },
    {
      "epoch": 2.074074074074074,
      "grad_norm": 0.723706841468811,
      "learning_rate": 2.63304304741037e-05,
      "loss": 0.1336,
      "step": 1400
    },
    {
      "epoch": 2.074074074074074,
      "eval_loss": 0.3489687144756317,
      "eval_runtime": 21.1317,
      "eval_samples_per_second": 3.123,
      "eval_steps_per_second": 3.123,
      "step": 1400
    },
    {
      "epoch": 2.088888888888889,
      "grad_norm": 0.6742525100708008,
      "learning_rate": 2.55745796505105e-05,
      "loss": 0.1557,
      "step": 1410
    },
    {
      "epoch": 2.1037037037037036,
      "grad_norm": 0.6270719170570374,
      "learning_rate": 2.482599045976059e-05,
      "loss": 0.1765,
      "step": 1420
    },
    {
      "epoch": 2.1185185185185187,
      "grad_norm": 0.6551542282104492,
      "learning_rate": 2.408488545605265e-05,
      "loss": 0.1931,
      "step": 1430
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 0.5555148720741272,
      "learning_rate": 2.3351484968550264e-05,
      "loss": 0.1476,
      "step": 1440
    },
    {
      "epoch": 2.148148148148148,
      "grad_norm": 0.6846712231636047,
      "learning_rate": 2.2626007035878377e-05,
      "loss": 0.168,
      "step": 1450
    },
    {
      "epoch": 2.162962962962963,
      "grad_norm": 0.6063275933265686,
      "learning_rate": 2.190866734130092e-05,
      "loss": 0.1592,
      "step": 1460
    },
    {
      "epoch": 2.1777777777777776,
      "grad_norm": 0.7173780798912048,
      "learning_rate": 2.1199679148598435e-05,
      "loss": 0.1757,
      "step": 1470
    },
    {
      "epoch": 2.1925925925925926,
      "grad_norm": 0.7530314922332764,
      "learning_rate": 2.0499253238665282e-05,
      "loss": 0.1466,
      "step": 1480
    },
    {
      "epoch": 2.2074074074074073,
      "grad_norm": 0.5837429761886597,
      "learning_rate": 1.9807597846844738e-05,
      "loss": 0.146,
      "step": 1490
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.7258330583572388,
      "learning_rate": 1.9124918601021125e-05,
      "loss": 0.1882,
      "step": 1500
    },
    {
      "epoch": 2.2222222222222223,
      "eval_loss": 0.35063865780830383,
      "eval_runtime": 21.0523,
      "eval_samples_per_second": 3.135,
      "eval_steps_per_second": 3.135,
      "step": 1500
    },
    {
      "epoch": 2.237037037037037,
      "grad_norm": 0.6126598715782166,
      "learning_rate": 1.8451418460486907e-05,
      "loss": 0.199,
      "step": 1510
    },
    {
      "epoch": 2.251851851851852,
      "grad_norm": 0.6419903039932251,
      "learning_rate": 1.778729765560337e-05,
      "loss": 0.165,
      "step": 1520
    },
    {
      "epoch": 2.2666666666666666,
      "grad_norm": 0.6344788074493408,
      "learning_rate": 1.7132753628272402e-05,
      "loss": 0.1493,
      "step": 1530
    },
    {
      "epoch": 2.2814814814814817,
      "grad_norm": 0.629183292388916,
      "learning_rate": 1.648798097323743e-05,
      "loss": 0.1507,
      "step": 1540
    },
    {
      "epoch": 2.2962962962962963,
      "grad_norm": 0.6226695775985718,
      "learning_rate": 1.5853171380230793e-05,
      "loss": 0.1516,
      "step": 1550
    },
    {
      "epoch": 2.311111111111111,
      "grad_norm": 0.6596356630325317,
      "learning_rate": 1.5228513576984633e-05,
      "loss": 0.1374,
      "step": 1560
    },
    {
      "epoch": 2.325925925925926,
      "grad_norm": 1.4632835388183594,
      "learning_rate": 1.4614193273122563e-05,
      "loss": 0.1463,
      "step": 1570
    },
    {
      "epoch": 2.3407407407407406,
      "grad_norm": 0.8503889441490173,
      "learning_rate": 1.4010393104948549e-05,
      "loss": 0.1853,
      "step": 1580
    },
    {
      "epoch": 2.3555555555555556,
      "grad_norm": 0.7177648544311523,
      "learning_rate": 1.3417292581149387e-05,
      "loss": 0.1554,
      "step": 1590
    },
    {
      "epoch": 2.3703703703703702,
      "grad_norm": 0.5804014205932617,
      "learning_rate": 1.283506802942719e-05,
      "loss": 0.1967,
      "step": 1600
    },
    {
      "epoch": 2.3703703703703702,
      "eval_loss": 0.3506012260913849,
      "eval_runtime": 20.96,
      "eval_samples_per_second": 3.149,
      "eval_steps_per_second": 3.149,
      "step": 1600
    },
    {
      "epoch": 2.3851851851851853,
      "grad_norm": 0.6035330295562744,
      "learning_rate": 1.2263892544077437e-05,
      "loss": 0.1609,
      "step": 1610
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.7231675386428833,
      "learning_rate": 1.1703935934528326e-05,
      "loss": 0.2024,
      "step": 1620
    },
    {
      "epoch": 2.414814814814815,
      "grad_norm": 0.6771546602249146,
      "learning_rate": 1.1155364674856833e-05,
      "loss": 0.1234,
      "step": 1630
    },
    {
      "epoch": 2.4296296296296296,
      "grad_norm": 0.6949026584625244,
      "learning_rate": 1.0618341854296177e-05,
      "loss": 0.1601,
      "step": 1640
    },
    {
      "epoch": 2.4444444444444446,
      "grad_norm": 0.6563869714736938,
      "learning_rate": 1.0093027128749721e-05,
      "loss": 0.177,
      "step": 1650
    },
    {
      "epoch": 2.4592592592592593,
      "grad_norm": 0.6613461375236511,
      "learning_rate": 9.579576673325619e-06,
      "loss": 0.1462,
      "step": 1660
    },
    {
      "epoch": 2.474074074074074,
      "grad_norm": 0.6096212267875671,
      "learning_rate": 9.078143135906153e-06,
      "loss": 0.141,
      "step": 1670
    },
    {
      "epoch": 2.488888888888889,
      "grad_norm": 0.9490024447441101,
      "learning_rate": 8.588875591765838e-06,
      "loss": 0.1329,
      "step": 1680
    },
    {
      "epoch": 2.5037037037037035,
      "grad_norm": 0.6328006386756897,
      "learning_rate": 8.111919499251653e-06,
      "loss": 0.1662,
      "step": 1690
    },
    {
      "epoch": 2.5185185185185186,
      "grad_norm": 0.7019939422607422,
      "learning_rate": 7.647416656538464e-06,
      "loss": 0.2248,
      "step": 1700
    },
    {
      "epoch": 2.5185185185185186,
      "eval_loss": 0.3511141836643219,
      "eval_runtime": 20.9636,
      "eval_samples_per_second": 3.148,
      "eval_steps_per_second": 3.148,
      "step": 1700
    },
    {
      "epoch": 2.533333333333333,
      "grad_norm": 0.6489264965057373,
      "learning_rate": 7.195505159472726e-06,
      "loss": 0.1709,
      "step": 1710
    },
    {
      "epoch": 2.5481481481481483,
      "grad_norm": 0.8086082339286804,
      "learning_rate": 6.756319360516855e-06,
      "loss": 0.1314,
      "step": 1720
    },
    {
      "epoch": 2.562962962962963,
      "grad_norm": 0.6562024354934692,
      "learning_rate": 6.3299898288064816e-06,
      "loss": 0.1346,
      "step": 1730
    },
    {
      "epoch": 2.5777777777777775,
      "grad_norm": 0.6466663479804993,
      "learning_rate": 5.916643311332437e-06,
      "loss": 0.1602,
      "step": 1740
    },
    {
      "epoch": 2.5925925925925926,
      "grad_norm": 0.5038801431655884,
      "learning_rate": 5.516402695259165e-06,
      "loss": 0.1555,
      "step": 1750
    },
    {
      "epoch": 2.6074074074074076,
      "grad_norm": 0.7773799896240234,
      "learning_rate": 5.12938697139056e-06,
      "loss": 0.1363,
      "step": 1760
    },
    {
      "epoch": 2.6222222222222222,
      "grad_norm": 0.6247669458389282,
      "learning_rate": 4.7557111987942325e-06,
      "loss": 0.1477,
      "step": 1770
    },
    {
      "epoch": 2.637037037037037,
      "grad_norm": 0.7346141338348389,
      "learning_rate": 4.395486470594645e-06,
      "loss": 0.1616,
      "step": 1780
    },
    {
      "epoch": 2.651851851851852,
      "grad_norm": 0.9399057626724243,
      "learning_rate": 4.048819880945337e-06,
      "loss": 0.1582,
      "step": 1790
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.7099402546882629,
      "learning_rate": 3.7158144931900395e-06,
      "loss": 0.1419,
      "step": 1800
    },
    {
      "epoch": 2.6666666666666665,
      "eval_loss": 0.3490055203437805,
      "eval_runtime": 20.933,
      "eval_samples_per_second": 3.153,
      "eval_steps_per_second": 3.153,
      "step": 1800
    },
    {
      "epoch": 2.6814814814814816,
      "grad_norm": 0.6377344727516174,
      "learning_rate": 3.3965693092221142e-06,
      "loss": 0.1235,
      "step": 1810
    },
    {
      "epoch": 2.696296296296296,
      "grad_norm": 0.685843288898468,
      "learning_rate": 3.0911792400514617e-06,
      "loss": 0.1631,
      "step": 1820
    },
    {
      "epoch": 2.7111111111111112,
      "grad_norm": 0.6286993026733398,
      "learning_rate": 2.7997350775876953e-06,
      "loss": 0.1208,
      "step": 1830
    },
    {
      "epoch": 2.725925925925926,
      "grad_norm": 0.7424715757369995,
      "learning_rate": 2.522323467647819e-06,
      "loss": 0.152,
      "step": 1840
    },
    {
      "epoch": 2.7407407407407405,
      "grad_norm": 0.8301324248313904,
      "learning_rate": 2.2590268841966357e-06,
      "loss": 0.1349,
      "step": 1850
    },
    {
      "epoch": 2.7555555555555555,
      "grad_norm": 0.7472831010818481,
      "learning_rate": 2.009923604827341e-06,
      "loss": 0.1507,
      "step": 1860
    },
    {
      "epoch": 2.7703703703703706,
      "grad_norm": 0.761846661567688,
      "learning_rate": 1.7750876874897626e-06,
      "loss": 0.137,
      "step": 1870
    },
    {
      "epoch": 2.785185185185185,
      "grad_norm": 0.6726563572883606,
      "learning_rate": 1.554588948473068e-06,
      "loss": 0.1756,
      "step": 1880
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.75887531042099,
      "learning_rate": 1.3484929416495095e-06,
      "loss": 0.1674,
      "step": 1890
    },
    {
      "epoch": 2.814814814814815,
      "grad_norm": 0.7392679452896118,
      "learning_rate": 1.1568609389853546e-06,
      "loss": 0.1606,
      "step": 1900
    },
    {
      "epoch": 2.814814814814815,
      "eval_loss": 0.3498070240020752,
      "eval_runtime": 20.9472,
      "eval_samples_per_second": 3.151,
      "eval_steps_per_second": 3.151,
      "step": 1900
    },
    {
      "epoch": 2.8296296296296295,
      "grad_norm": 0.7913556098937988,
      "learning_rate": 9.7974991232489e-07,
      "loss": 0.1926,
      "step": 1910
    },
    {
      "epoch": 2.8444444444444446,
      "grad_norm": 0.8526055812835693,
      "learning_rate": 8.172125164527311e-07,
      "loss": 0.1322,
      "step": 1920
    },
    {
      "epoch": 2.859259259259259,
      "grad_norm": 0.7305667996406555,
      "learning_rate": 6.692970734397175e-07,
      "loss": 0.1291,
      "step": 1930
    },
    {
      "epoch": 2.8740740740740742,
      "grad_norm": 0.7389526963233948,
      "learning_rate": 5.360475582768087e-07,
      "loss": 0.1653,
      "step": 1940
    },
    {
      "epoch": 2.888888888888889,
      "grad_norm": 0.5712197422981262,
      "learning_rate": 4.175035858013987e-07,
      "loss": 0.1755,
      "step": 1950
    },
    {
      "epoch": 2.9037037037037035,
      "grad_norm": 0.7885658144950867,
      "learning_rate": 3.13700398919925e-07,
      "loss": 0.2154,
      "step": 1960
    },
    {
      "epoch": 2.9185185185185185,
      "grad_norm": 0.7624359130859375,
      "learning_rate": 2.2466885813018923e-07,
      "loss": 0.1192,
      "step": 1970
    },
    {
      "epoch": 2.9333333333333336,
      "grad_norm": 0.6316121816635132,
      "learning_rate": 1.5043543234660727e-07,
      "loss": 0.1645,
      "step": 1980
    },
    {
      "epoch": 2.948148148148148,
      "grad_norm": 0.7574858069419861,
      "learning_rate": 9.10221910310316e-08,
      "loss": 0.1576,
      "step": 1990
    },
    {
      "epoch": 2.962962962962963,
      "grad_norm": 0.7249342799186707,
      "learning_rate": 4.644679763155524e-08,
      "loss": 0.1919,
      "step": 2000
    },
    {
      "epoch": 2.962962962962963,
      "eval_loss": 0.34911325573921204,
      "eval_runtime": 20.9389,
      "eval_samples_per_second": 3.152,
      "eval_steps_per_second": 3.152,
      "step": 2000
    },
    {
      "epoch": 2.977777777777778,
      "grad_norm": 0.6256685256958008,
      "learning_rate": 1.672250433119582e-08,
      "loss": 0.1459,
      "step": 2010
    },
    {
      "epoch": 2.9925925925925925,
      "grad_norm": 0.7394052147865295,
      "learning_rate": 1.8581481080415243e-09,
      "loss": 0.1576,
      "step": 2020
    },
    {
      "epoch": 3.0,
      "step": 2025,
      "total_flos": 1.4821210659704832e+17,
      "train_loss": 0.04087679942448934,
      "train_runtime": 2650.172,
      "train_samples_per_second": 3.056,
      "train_steps_per_second": 0.764
    }
  ],
  "logging_steps": 10,
  "max_steps": 2025,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4821210659704832e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
